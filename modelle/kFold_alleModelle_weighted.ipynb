{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hier sind k-fold cross-validation Scores für die Modelle Logistic Regression, Random Forest und K-Nearest Neighbors wobei die Daten gewichtet wurden. (tödliche bzw tödliche/ schwere Unfälle mit Gewichtung 500) \n",
    "\n",
    "1. tödliche Unfälle vs. nicht tödliche Unfälle\n",
    "\n",
    " alle Modelle haben eine geringe Precision, d.h. viele False Positives, d.h. viele fälschlicherweise als tod klassifiziert werden. Der F1 Score ist dementsprechend auch gering, d.h. das Modell hat Schwierigkeiten die tödlichen Unfälle zu erkennen.\n",
    "\n",
    "\n",
    "2. tödliche und schwere Unfälle vs. leichte Unfälle \n",
    "\n",
    "Der F1 Score ist etwas besser, d.h. das Modell hat weniger Schwierigkeiten die schweren oder tödlichen Unfälle zu erkennen, aber die Scores zeigen immer noch problematiche Precision und Recall Werte.\n",
    "\n",
    "Nächste Schritte:\n",
    "\n",
    "- Überlegen, ob für den F1 Score Precision, Recall gewichtet werden soll? F1Beta-Score (Beta=1) = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "- Hyperparameteroptimierung, Gewichte in Hpyerparametern einbeziehen (Erfahrungen mit Werten aus zB Blockposts oder Helena fragen) "
   ],
   "id": "c50d605a13432328"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ea87cd736612a046"
  },
  {
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD:modelle/kFold_linRegVSrandomForestVSknn.ipynb
     "end_time": "2024-06-22T08:01:43.059236Z",
     "start_time": "2024-06-22T08:00:50.426689Z"
=======
     "end_time": "2024-06-22T10:19:32.988168Z",
     "start_time": "2024-06-22T10:17:25.424088Z"
>>>>>>> refs/remotes/origin/main:modelle/kFold_alleModelle_weighted.ipynb
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = pd.read_csv('../data/GeneralDatensatz18-21ohneGeo.csv', sep=';')\n",
    "\n",
    "X=df[['UMONAT','USTUNDE','UWOCHENTAG','UART','USTRZUSTAND','BEZ','UTYP1','ULICHTVERH','IstRad','IstPKW','IstFuss','IstKrad','IstGkfz','IstSonstige']]\n",
    "#für tödliche Unfälle\n",
    "y=(df['UKATEGORIE'] == 1).astype(int)\n",
    "\n",
    "\n",
    "# KFold-Konfiguration\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Logistische Regression\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight={0:1, 1: 500})\n",
    "accuracy_log = cross_val_score(log_reg, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy Logistic Regression (k-fold):\", accuracy_log.mean())\n",
    "\n",
    "\n",
    "recall_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='recall')\n",
    "print(\"Recall Logistic Regression  (k-fold):\", recall_reg.mean())\n",
    "\n",
    "precision_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='precision')\n",
    "print(\"Precision Logistic Regression (k-fold):\", precision_reg.mean())\n",
    "\n",
    "f1_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='f1')\n",
    "print(\"F1 Logistic Regression (k-fold):\", f1_reg.mean())\n",
    "\n",
    "roc_auc_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='roc_auc')\n",
    "print(\"Roc Auc Logistic Regression (k-fold):\", roc_auc_reg.mean())\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "rf_clas = RandomForestClassifier(n_estimators=100, max_depth=5,random_state=42, class_weight={0:1, 1: 1000})\n",
    "accuracy_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy Random Forest (k-fold):\", accuracy_rf.mean())\n",
    "\n",
    "recall_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='recall')\n",
    "print(\"Recall Random Forest (k-fold):\", recall_rf.mean())\n",
    "\n",
    "precision_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='precision')\n",
    "print(\"Precision Random Forest (k-fold):\", precision_rf.mean())\n",
    "\n",
    "f1_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='f1')\n",
    "print(\"F1 Random Forest (k-fold):\", f1_rf.mean())\n",
    "\n",
    "roc_auc_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='roc_auc')\n",
    "print(\"Roc Auc Random Forest (k-fold):\", roc_auc_rf.mean())\n",
    "\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_clas = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "accuracy_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy K-Nearest Neighbors (k-fold):\", accuracy_knn.mean())\n",
    "\n",
    "recall_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='recall')\n",
    "print(\"Recall K-Nearest Neighbors (k-fold):\", recall_knn.mean())\n",
    "\n",
    "precision_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='precision')\n",
    "print(\"Precision K-Nearest Neighbors (k-fold):\", precision_knn.mean())\n",
    "\n",
    "f1_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='f1')\n",
    "print(\"F1 K-Nearest Neighbors (k-fold):\", f1_knn.mean())\n"
   ],
   "id": "b928bb89b9907bb9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD:modelle/kFold_linRegVSrandomForestVSknn.ipynb
      "Accuracy Logistic Regression (k-fold): 0.5262180882613245\n",
      "Recall Logistic Regression  (k-fold): 0.8192816066588857\n",
      "Precision Logistic Regression (k-fold): 0.005265836260413358\n",
      "F1 Logistic Regression (k-fold): 0.010461533399287426\n",
      "Roc Auc Logistic Regression (k-fold): 0.80684517698557\n",
=======
      "Accuracy Logistic Regression (k-fold): 0.7150720621102987\n",
      "Recall Logistic Regression  (k-fold): 0.768730186752627\n",
      "Precision Logistic Regression (k-fold): 0.008250772076189515\n",
      "F1 Logistic Regression (k-fold): 0.01631415466819965\n",
      "Roc Auc Logistic Regression (k-fold): 0.8103577323703579\n",
>>>>>>> refs/remotes/origin/main:modelle/kFold_alleModelle_weighted.ipynb
      "Accuracy Random Forest (k-fold): 0.7333480978585645\n",
      "Recall Random Forest (k-fold): 0.7103605915667627\n",
      "Precision Random Forest (k-fold): 0.00866650527031301\n",
      "F1 Random Forest (k-fold): 0.017099080857978316\n",
      "Roc Auc Random Forest (k-fold): 0.7844327233273172\n",
      "Accuracy K-Nearest Neighbors (k-fold): 0.9967875801060593\n",
      "Recall K-Nearest Neighbors (k-fold): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision K-Nearest Neighbors (k-fold): 0.0\n",
      "F1 K-Nearest Neighbors (k-fold): 0.0\n"
     ]
    }
   ],
<<<<<<< HEAD:modelle/kFold_linRegVSrandomForestVSknn.ipynb
   "execution_count": 1
=======
   "execution_count": 3
>>>>>>> refs/remotes/origin/main:modelle/kFold_alleModelle_weighted.ipynb
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "zB Logistische Regression:\n",
    "- Recall: 76 % der tödlich Fälle wurden als tödlich erkannt\n",
    "- Precision: 0,8 % der erkannten tödlich Fälle sind tatsächlich tödlich Fälle\n",
    "( Precision = tp / (tp + fp) , d.h. wenn es viele False Positive gibt, viele fälschlicherweise als tod klassifiziert werden, dann wird der Nenner klein) \n"
   ],
   "id": "7278edc2a96a60bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD:modelle/kFold_linRegVSrandomForestVSknn.ipynb
     "end_time": "2024-06-22T08:02:05.143351Z",
     "start_time": "2024-06-22T08:01:43.060706Z"
=======
     "end_time": "2024-06-22T10:21:17.806245Z",
     "start_time": "2024-06-22T10:19:32.992799Z"
>>>>>>> refs/remotes/origin/main:modelle/kFold_alleModelle_weighted.ipynb
    }
   },
   "cell_type": "code",
   "source": [
    "#für tödliche und schwere vs. leichte Unfälle\n",
    "y = df['UKATEGORIE'].isin([1, 2]).astype(int)\n",
    "# -> 1 ist schwer oder tödlich, 0 ist leicht\n",
    "\n",
    "# KFold-Konfiguration\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Logistische Regression\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight={0:1, 1: 500})\n",
    "accuracy_log = cross_val_score(log_reg, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy Logistic Regression (k-fold):\", accuracy_log.mean())\n",
    "\n",
    "\n",
    "recall_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='recall')\n",
    "print(\"Recall Logistic Regression  (k-fold):\", recall_reg.mean())\n",
    "\n",
    "precision_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='precision')\n",
    "print(\"Precision Logistic Regression (k-fold):\", precision_reg.mean())\n",
    "\n",
    "f1_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='f1')\n",
    "print(\"F1 Logistic Regression (k-fold):\", f1_reg.mean())\n",
    "\n",
    "roc_auc_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='roc_auc')\n",
    "print(\"Roc Auc Logistic Regression (k-fold):\", roc_auc_reg.mean())\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "rf_clas = RandomForestClassifier(n_estimators=100, max_depth=5,random_state=42, class_weight={0:1, 1: 100})\n",
    "accuracy_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy Random Forest (k-fold):\", accuracy_rf.mean())\n",
    "\n",
    "recall_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='recall')\n",
    "print(\"Recall Random Forest (k-fold):\", recall_rf.mean())\n",
    "\n",
    "precision_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='precision')\n",
    "print(\"Precision Random Forest (k-fold):\", precision_rf.mean())\n",
    "\n",
    "f1_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='f1')\n",
    "print(\"F1 Random Forest (k-fold):\", f1_rf.mean())\n",
    "\n",
    "roc_auc_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='roc_auc')\n",
    "print(\"Roc Auc Random Forest (k-fold):\", roc_auc_rf.mean())\n",
    "\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_clas = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "accuracy_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy K-Nearest Neighbors (k-fold):\", accuracy_knn.mean())\n",
    "\n",
    "recall_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='recall')\n",
    "print(\"Recall K-Nearest Neighbors (k-fold):\", recall_knn.mean())\n",
    "\n",
    "precision_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='precision')\n",
    "print(\"Precision K-Nearest Neighbors (k-fold):\", precision_knn.mean())\n",
    "\n",
    "f1_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='f1')\n",
    "print(\"F1 K-Nearest Neighbors (k-fold):\", f1_knn.mean())\n"
   ],
   "id": "ee7773ac52304c27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD:modelle/kFold_linRegVSrandomForestVSknn.ipynb
      "Accuracy Logistic Regression (k-fold): 0.8461231963769842\n",
      "Accuracy Random Forest (k-fold): 0.8409953077594319\n",
      "Accuracy K-Nearest Neighbors (k-fold): 0.8120834371448462\n"
     ]
    }
   ],
   "execution_count": 2
=======
      "Accuracy Logistic Regression (k-fold): 0.1537371408091796\n",
      "Recall Logistic Regression  (k-fold): 1.0\n",
      "Precision Logistic Regression (k-fold): 0.1537371408091796\n",
      "F1 Logistic Regression (k-fold): 0.26650076510709847\n",
      "Roc Auc Logistic Regression (k-fold): 0.6392911582854681\n",
      "Accuracy Random Forest (k-fold): 0.1537371408091796\n",
      "Recall Random Forest (k-fold): 1.0\n",
      "Precision Random Forest (k-fold): 0.1537371408091796\n",
      "F1 Random Forest (k-fold): 0.26650076510709847\n",
      "Roc Auc Random Forest (k-fold): 0.66067902832801\n",
      "Accuracy K-Nearest Neighbors (k-fold): 0.8091104764707573\n",
      "Recall K-Nearest Neighbors (k-fold): 0.11347623903069588\n",
      "Precision K-Nearest Neighbors (k-fold): 0.24217967246100125\n",
      "F1 K-Nearest Neighbors (k-fold): 0.15443972821930768\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "zB Logistische Regression:\n",
    "- Recall: 100 % der schweren/tödlichen Fälle wurden als schweren/tödlichen erkannt\n",
    "- Precision: 15 % der erkannten schweren/tödlichen Fälle sind tatsächlich schweren/tödlichen Fälle\n",
    "- ROC AUC Logistic Regression: Der Wert von etwa 0,6393 zeigt, dass das Modell Logistic Regression eine mäßige Fähigkeit hat, zwischen den Klassen zu unterscheiden."
   ],
   "id": "26889395b7c37815"
>>>>>>> refs/remotes/origin/main:modelle/kFold_alleModelle_weighted.ipynb
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2c38a6fbfebf1983"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
