{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Logistische Regression\n",
    "\n",
    "**Lasso-** oder **Ridge-Regularisierung** hilft Overfitting zu vermeiden. Der F-beta Score kann dann verwendet werden, um die Leistung des regulierten Modells zu bewerten.\n",
    "- **Lasso** (L1): Setzt einige Koeffizienten auf null, was einer Feature-Selektion entspricht.\n",
    "- **Ridge** (L2): Schrumpft die Koeffizienten, ohne sie auf null zu setzen, was die Varianz reduziert. \n"
   ],
   "id": "c0b745c8f0a6e936"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Lade den unbalancierten Datensatz.\n",
    "2. Splitte den Datensatz in Trainings- und Testdaten.\n",
    "3. Trainiere ein Modell mit Ridge-Regularisierung.\n",
    "4. Trainiere ein Modell mit Lasso-Regularisierung.\n",
    "5. Berechne den F-beta Score für beide Modelle auf den Testdaten."
   ],
   "id": "9bd498057a994392"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T13:49:03.487440Z",
     "start_time": "2024-07-31T13:48:59.105365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Lade den Datensatz\n",
    "train_data_loaded = pd.read_csv('../data/train_data_2024-07-31.csv')\n",
    "X = train_data_loaded.drop(columns=['UKATEGORIE'])\n",
    "y = train_data_loaded['UKATEGORIE']\n",
    "\n",
    "# Splitte den Datensatz in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Modell mit Ridge-Regularisierung (L2)\n",
    "model_ridge = LogisticRegression(penalty='l2', solver='lbfgs', C=1.0, max_iter = 150, class_weight={0: 1, 1: 9})\n",
    "model_ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = model_ridge.predict(X_test)\n",
    "fbeta_ridge = fbeta_score(y_test, y_pred_ridge, beta=2)\n",
    "print(f'Ridge (L2) F-beta Score: {fbeta_ridge}', '\\n')\n",
    "\n",
    "\n",
    "# Extrahiere die Koeffizienten\n",
    "coefficients = model_ridge.coef_\n",
    "\n",
    "# Erstelle ein DataFrame mit den Features und ihren Koeffizienten\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': coefficients.flatten()\n",
    "})\n",
    "\n",
    "# Sortiere das DataFrame nach den absoluten Werten der Koeffizienten\n",
    "coeff_df['Abs_Coefficient'] = coeff_df['Coefficient'].abs()\n",
    "coeff_df = coeff_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Identifiziere die wichtigsten Features\n",
    "important_features = coeff_df.head(5)  # z.B. die Top 5 Features\n",
    "print(important_features[['Feature', 'Coefficient']], '\\n')\n",
    "\n",
    "\n",
    "# Modell mit Lasso-Regularisierung (L1)\n",
    "model_lasso = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, max_iter = 150, class_weight={0: 1, 1: 9})\n",
    "model_lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = model_lasso.predict(X_test)\n",
    "fbeta_lasso = fbeta_score(y_test, y_pred_lasso, beta=2)\n",
    "print(f'Lasso (L1) F-beta Score: {fbeta_lasso}', '\\n')\n",
    "\n",
    "#Zeige die Koeffizienten der Ridge-Regularisierung\n",
    "#Bei der Lasso-Regularisierung können Sie die korrelierten Features identifizieren, indem Sie die Koeffizienten des trainierten Modells analysieren. Features mit nicht-null Koeffizienten sind diejenigen, die vom Modell als relevant erachtet werden. \n",
    "\n",
    "\n",
    "# Extrahiere die nicht-null Koeffizienten\n",
    "coef_series = pd.Series(model_lasso.coef_[0])\n",
    "relevant_features = coef_series[coef_series != 0].index\n",
    "\n",
    "# Erstelle ein DataFrame der relevanten Features\n",
    "X_relevant = X_train.iloc[:, relevant_features]\n",
    "\n",
    "# Berechne die Korrelationsmatrix der relevanten Features\n",
    "correlation_matrix = X_relevant.corr()\n",
    "\n",
    "# Extrahiere die nicht-null Koeffizienten\n",
    "coef_series = pd.Series(model_lasso.coef_[0])\n",
    "relevant_features = coef_series[coef_series != 0].index\n",
    "\n",
    "# Anzahl der auf null gesetzten Features\n",
    "num_null_features = (coef_series == 0).sum()\n",
    "print(f'Lasso-Regutlierung: Anzahl der auf null gesetzten Features: {num_null_features}')\n",
    "\n",
    "print(\"Korrelationsmatrix der relevanten Features:\")\n",
    "print(correlation_matrix)"
   ],
   "id": "45415edb94a35f9c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anne/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (L2) F-beta Score: 0.46373416623286484 \n",
      "\n",
      "       Feature  Coefficient\n",
      "8       IstPKW    -0.390694\n",
      "10     IstKrad     0.356974\n",
      "9      IstFuss     0.334548\n",
      "6   ULICHTVERH     0.245873\n",
      "7       IstRad    -0.236600 \n",
      "\n",
      "Lasso (L1) F-beta Score: 0.4696655548544127 \n",
      "\n",
      "Lasso-Regutlierung: Anzahl der auf null gesetzten Features: 0\n",
      "Korrelationsmatrix der relevanten Features:\n",
      "                UJAHR    UMONAT   USTUNDE  UWOCHENTAG      UART     UTYP1  \\\n",
      "UJAHR        1.000000  0.042393  0.012306   -0.002894 -0.014854 -0.006403   \n",
      "UMONAT       0.042393  1.000000  0.003593    0.013820 -0.025604  0.000857   \n",
      "USTUNDE      0.012306  0.003593  1.000000    0.015724 -0.008369  0.030355   \n",
      "UWOCHENTAG  -0.002894  0.013820  0.015724    1.000000  0.000182 -0.001436   \n",
      "UART        -0.014854 -0.025604 -0.008369    0.000182  1.000000 -0.282726   \n",
      "UTYP1       -0.006403  0.000857  0.030355   -0.001436 -0.282726  1.000000   \n",
      "ULICHTVERH  -0.003904  0.071547  0.237957    0.019494  0.053933 -0.063918   \n",
      "IstRad       0.009018  0.007976 -0.004651   -0.000623 -0.020951 -0.155848   \n",
      "IstPKW      -0.020618 -0.025560  0.032636    0.001702  0.137009  0.073420   \n",
      "IstFuss     -0.026274 -0.014401  0.032556    0.008028  0.390240  0.034949   \n",
      "IstKrad     -0.011966  0.038969  0.025898   -0.011210 -0.148852 -0.006214   \n",
      "IstGkfz     -0.004665 -0.012977 -0.073800   -0.008742 -0.027213  0.059221   \n",
      "IstSonstige  0.025032  0.006826 -0.042332   -0.001733 -0.099306  0.068650   \n",
      "USTRZUSTAND  0.057930  0.030015 -0.000557   -0.005024 -0.002124 -0.052872   \n",
      "LOCKDOWN     0.404317 -0.003903  0.006815   -0.008344 -0.003890  0.004283   \n",
      "COVID        0.816222  0.110085  0.013683   -0.020643 -0.006703 -0.005392   \n",
      "\n",
      "             ULICHTVERH    IstRad    IstPKW   IstFuss   IstKrad   IstGkfz  \\\n",
      "UJAHR         -0.003904  0.009018 -0.020618 -0.026274 -0.011966 -0.004665   \n",
      "UMONAT         0.071547  0.007976 -0.025560 -0.014401  0.038969 -0.012977   \n",
      "USTUNDE        0.237957 -0.004651  0.032636  0.032556  0.025898 -0.073800   \n",
      "UWOCHENTAG     0.019494 -0.000623  0.001702  0.008028 -0.011210 -0.008742   \n",
      "UART           0.053933 -0.020951  0.137009  0.390240 -0.148852 -0.027213   \n",
      "UTYP1         -0.063918 -0.155848  0.073420  0.034949 -0.006214  0.059221   \n",
      "ULICHTVERH     1.000000 -0.113314  0.019021  0.095066 -0.031134 -0.043064   \n",
      "IstRad        -0.113314  1.000000 -0.244594 -0.176230 -0.293536 -0.051551   \n",
      "IstPKW         0.019021 -0.244594  1.000000 -0.131425 -0.136944 -0.113678   \n",
      "IstFuss        0.095066 -0.176230 -0.131425  1.000000 -0.123469 -0.034256   \n",
      "IstKrad       -0.031134 -0.293536 -0.136944 -0.123469  1.000000 -0.038945   \n",
      "IstGkfz       -0.043064 -0.051551 -0.113678 -0.034256 -0.038945  1.000000   \n",
      "IstSonstige   -0.015361 -0.110177 -0.299070 -0.037174 -0.081660 -0.027606   \n",
      "USTRZUSTAND    0.250075 -0.112507  0.013354  0.054692  0.000774 -0.002296   \n",
      "LOCKDOWN       0.045749 -0.013001  0.003244 -0.000184 -0.025564  0.000199   \n",
      "COVID          0.002809  0.010237 -0.015730 -0.018937 -0.015621 -0.007049   \n",
      "\n",
      "             IstSonstige  USTRZUSTAND  LOCKDOWN     COVID  \n",
      "UJAHR           0.025032     0.057930  0.404317  0.816222  \n",
      "UMONAT          0.006826     0.030015 -0.003903  0.110085  \n",
      "USTUNDE        -0.042332    -0.000557  0.006815  0.013683  \n",
      "UWOCHENTAG     -0.001733    -0.005024 -0.008344 -0.020643  \n",
      "UART           -0.099306    -0.002124 -0.003890 -0.006703  \n",
      "UTYP1           0.068650    -0.052872  0.004283 -0.005392  \n",
      "ULICHTVERH     -0.015361     0.250075  0.045749  0.002809  \n",
      "IstRad         -0.110177    -0.112507 -0.013001  0.010237  \n",
      "IstPKW         -0.299070     0.013354  0.003244 -0.015730  \n",
      "IstFuss        -0.037174     0.054692 -0.000184 -0.018937  \n",
      "IstKrad        -0.081660     0.000774 -0.025564 -0.015621  \n",
      "IstGkfz        -0.027606    -0.002296  0.000199 -0.007049  \n",
      "IstSonstige     1.000000    -0.016300 -0.001615  0.016874  \n",
      "USTRZUSTAND    -0.016300     1.000000  0.094155  0.054731  \n",
      "LOCKDOWN       -0.001615     0.094155  1.000000  0.669435  \n",
      "COVID           0.016874     0.054731  0.669435  1.000000  \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ridge-Regularisierung (L2)\n",
    "##### Vorteile:  \n",
    "Reduziert Overfitting, indem es die Größe der Koeffizienten beschränkt.\n",
    "Funktioniert gut, wenn alle Features relevant sind.\n",
    "Stabilisiert die Lösung, besonders bei multikollinearen Daten.\n",
    "##### Nachteile:  \n",
    "Kann nicht irrelevante Features vollständig eliminieren (Koeffizienten werden nur klein, aber nicht null).\n",
    "Kann bei sehr vielen irrelevanten Features weniger effektiv sein.\n",
    "## Lasso-Regularisierung (L1)\n",
    "##### Vorteile:  \n",
    "Kann irrelevante Features vollständig eliminieren (Koeffizienten werden null), was zu sparsamen Modellen führt.\n",
    "Automatische Feature-Selektion, was die Interpretierbarkeit verbessert.\n",
    "##### Nachteile:\n",
    "Kann bei hoch korrelierten Features instabil sein (wählt zufällig eines der korrelierten Features aus).\n",
    "Kann bei sehr vielen relevanten Features weniger effektiv sein, da es einige Koeffizienten auf null setzen könnte."
   ],
   "id": "fb78cdaf6993c16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T13:49:03.491094Z",
     "start_time": "2024-07-31T13:49:03.489115Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e8178316beeeaa31",
   "outputs": [],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
