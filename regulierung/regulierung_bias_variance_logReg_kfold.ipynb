{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Logistische Regression\n",
    "\n",
    "**Lasso-** oder **Ridge-Regularisierung** hilft Overfitting zu vermeiden. Der F-beta Score kann dann verwendet werden, um die Leistung des regulierten Modells zu bewerten.\n",
    "- **Lasso** (L1): Setzt einige Koeffizienten auf null, was einer Feature-Selektion entspricht.\n",
    "- **Ridge** (L2): Schrumpft die Koeffizienten, ohne sie auf null zu setzen, was die Varianz reduziert. \n"
   ],
   "id": "c0b745c8f0a6e936"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Lade den unbalancierten Datensatz.\n",
    "2. Splitte den Datensatz in Trainings- und Testdaten.\n",
    "3. Trainiere ein Modell mit Ridge-Regularisierung.\n",
    "4. Trainiere ein Modell mit Lasso-Regularisierung.\n",
    "5. Berechne den F-beta Score für beide Modelle auf den Testdaten."
   ],
   "id": "9bd498057a994392"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T13:19:48.597110Z",
     "start_time": "2024-08-07T13:19:03.787130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "\n",
    "# Lade den Datensatz\n",
    "train_data_loaded = pd.read_csv('../data/train_data_2024-08-01.csv')\n",
    "X = train_data_loaded.drop(columns=['UKATEGORIE'])\n",
    "y = train_data_loaded['UKATEGORIE']\n",
    "\n",
    "# Define the f-beta scorer\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Model with Ridge Regularization (L2)\n",
    "model_ridge = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=500, class_weight={0: 1, 1: 9})\n",
    "ridge_scores = cross_val_score(model_ridge, X, y, cv=skf, scoring=fbeta_scorer)\n",
    "print(f'Ridge (L2) F-beta Scores: {ridge_scores}')\n",
    "\n",
    "# Model with Lasso Regularization (L1)\n",
    "model_lasso = LogisticRegression(penalty='l1', solver='liblinear', max_iter= 500, class_weight={0: 1, 1: 9})\n",
    "lasso_scores = cross_val_score(model_lasso, X, y, cv=skf, scoring=fbeta_scorer)\n",
    "print(f'Lasso (L1) F-beta Scores: {lasso_scores}')\n",
    "\n",
    "# Train Ridge model on the full dataset for feature importance\n",
    "model_ridge.fit(X, y)\n",
    "coefficients = model_ridge.coef_\n",
    "\n",
    "# Create a DataFrame with the features and their coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': coefficients.flatten()\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by the absolute values of the coefficients\n",
    "coeff_df['Abs_Coefficient'] = coeff_df['Coefficient'].abs()\n",
    "coeff_df = coeff_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Identify the most important features\n",
    "important_features = coeff_df.head(15)\n",
    "print(important_features[['Feature', 'Coefficient']], '\\n')\n",
    "\n",
    "# Train Lasso model on the full dataset\n",
    "model_lasso.fit(X, y)\n",
    "\n",
    "# Extract the non-null coefficients\n",
    "coef_series = pd.Series(model_lasso.coef_[0])\n",
    "relevant_features = coef_series[coef_series != 0].index\n",
    "\n",
    "# Number of features set to null\n",
    "num_null_features = (coef_series == 0).sum()\n",
    "print(f'Lasso Regularization: Number of features set to null: {num_null_features}')\n",
    "\n",
    "# Create a DataFrame of the relevant features\n",
    "X_relevant = X.iloc[:, relevant_features]\n",
    "\n",
    "# Compute the correlation matrix of the relevant features\n",
    "correlation_matrix = X_relevant.corr()\n",
    "print(\"Correlation matrix of the relevant features:\")\n",
    "print(correlation_matrix)"
   ],
   "id": "45415edb94a35f9c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (L2) F-beta Scores: [0.48941093 0.47996438 0.48560035 0.47680758 0.47735564]\n",
      "Lasso (L1) F-beta Scores: [0.4881196  0.48151795 0.4866277  0.47395274 0.47912756]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Coefficient\n",
      "10      IstFuss     0.588610\n",
      "11      IstKrad     0.536222\n",
      "9        IstPKW    -0.525829\n",
      "12      IstGkfz     0.239196\n",
      "14  USTRZUSTAND    -0.172288\n",
      "7    ULICHTVERH     0.148435\n",
      "13  IstSonstige    -0.128293\n",
      "8        IstRad    -0.095739\n",
      "15     LOCKDOWN    -0.093456\n",
      "5          UART     0.069366\n",
      "6         UTYP1    -0.066737\n",
      "0           BEZ     0.040830\n",
      "2        UMONAT    -0.015615\n",
      "17       FERIEN     0.010070\n",
      "4    UWOCHENTAG    -0.007783 \n",
      "\n",
      "Lasso Regularization: Number of features set to null: 0\n",
      "Correlation matrix of the relevant features:\n",
      "                  BEZ     UJAHR    UMONAT   USTUNDE  UWOCHENTAG      UART  \\\n",
      "BEZ          1.000000  0.016262 -0.001105 -0.019728    0.004234  0.034043   \n",
      "UJAHR        0.016262  1.000000  0.044290  0.010382    0.000579 -0.019961   \n",
      "UMONAT      -0.001105  0.044290  1.000000  0.000265    0.011848 -0.023110   \n",
      "USTUNDE     -0.019728  0.010382  0.000265  1.000000    0.016865 -0.011654   \n",
      "UWOCHENTAG   0.004234  0.000579  0.011848  0.016865    1.000000  0.000621   \n",
      "UART         0.034043 -0.019961 -0.023110 -0.011654    0.000621  1.000000   \n",
      "UTYP1       -0.006259 -0.002802 -0.005130  0.032250    0.001495 -0.283473   \n",
      "ULICHTVERH  -0.026714 -0.008383  0.071050  0.233759    0.015986  0.048186   \n",
      "IstRad      -0.118909  0.008110  0.011817 -0.008445   -0.001897 -0.017276   \n",
      "IstPKW       0.066913 -0.018960 -0.025339  0.029771    0.004643  0.131909   \n",
      "IstFuss      0.016622 -0.028961 -0.016355  0.034862    0.009120  0.388010   \n",
      "IstKrad     -0.006322 -0.008044  0.035563  0.028067   -0.010063 -0.143372   \n",
      "IstGkfz      0.015766 -0.004085 -0.014454 -0.074143   -0.009899 -0.028179   \n",
      "IstSonstige  0.006377  0.024395  0.007821 -0.040327   -0.000001 -0.097953   \n",
      "USTRZUSTAND  0.016541  0.053997  0.023449 -0.000870   -0.001786  0.001156   \n",
      "LOCKDOWN     0.021933  0.403276 -0.004574  0.004128   -0.006948 -0.002427   \n",
      "COVID        0.022127  0.815720  0.110453  0.010513   -0.014890 -0.010124   \n",
      "FERIEN       0.000391  0.099374 -0.041115  0.024188   -0.003562 -0.019250   \n",
      "\n",
      "                UTYP1  ULICHTVERH    IstRad    IstPKW   IstFuss   IstKrad  \\\n",
      "BEZ         -0.006259   -0.026714 -0.118909  0.066913  0.016622 -0.006322   \n",
      "UJAHR       -0.002802   -0.008383  0.008110 -0.018960 -0.028961 -0.008044   \n",
      "UMONAT      -0.005130    0.071050  0.011817 -0.025339 -0.016355  0.035563   \n",
      "USTUNDE      0.032250    0.233759 -0.008445  0.029771  0.034862  0.028067   \n",
      "UWOCHENTAG   0.001495    0.015986 -0.001897  0.004643  0.009120 -0.010063   \n",
      "UART        -0.283473    0.048186 -0.017276  0.131909  0.388010 -0.143372   \n",
      "UTYP1        1.000000   -0.060233 -0.159359  0.069782  0.038497 -0.005861   \n",
      "ULICHTVERH  -0.060233    1.000000 -0.107653  0.020543  0.091589 -0.033449   \n",
      "IstRad      -0.159359   -0.107653  1.000000 -0.245358 -0.173208 -0.293760   \n",
      "IstPKW       0.069782    0.020543 -0.245358  1.000000 -0.137540 -0.132181   \n",
      "IstFuss      0.038497    0.091589 -0.173208 -0.137540  1.000000 -0.121841   \n",
      "IstKrad     -0.005861   -0.033449 -0.293760 -0.132181 -0.121841  1.000000   \n",
      "IstGkfz      0.060579   -0.044863 -0.048897 -0.114372 -0.036524 -0.041120   \n",
      "IstSonstige  0.068536   -0.014776 -0.111932 -0.300554 -0.033369 -0.081285   \n",
      "USTRZUSTAND -0.051445    0.253305 -0.110268  0.015806  0.054095 -0.003225   \n",
      "LOCKDOWN    -0.000509    0.044525 -0.013231  0.003775 -0.003363 -0.019247   \n",
      "COVID       -0.004396    0.001087  0.010581 -0.015290 -0.023098 -0.011263   \n",
      "FERIEN      -0.001381   -0.039335  0.008399 -0.005640 -0.020800  0.004639   \n",
      "\n",
      "              IstGkfz  IstSonstige  USTRZUSTAND  LOCKDOWN     COVID    FERIEN  \n",
      "BEZ          0.015766     0.006377     0.016541  0.021933  0.022127  0.000391  \n",
      "UJAHR       -0.004085     0.024395     0.053997  0.403276  0.815720  0.099374  \n",
      "UMONAT      -0.014454     0.007821     0.023449 -0.004574  0.110453 -0.041115  \n",
      "USTUNDE     -0.074143    -0.040327    -0.000870  0.004128  0.010513  0.024188  \n",
      "UWOCHENTAG  -0.009899    -0.000001    -0.001786 -0.006948 -0.014890 -0.003562  \n",
      "UART        -0.028179    -0.097953     0.001156 -0.002427 -0.010124 -0.019250  \n",
      "UTYP1        0.060579     0.068536    -0.051445 -0.000509 -0.004396 -0.001381  \n",
      "ULICHTVERH  -0.044863    -0.014776     0.253305  0.044525  0.001087 -0.039335  \n",
      "IstRad      -0.048897    -0.111932    -0.110268 -0.013231  0.010581  0.008399  \n",
      "IstPKW      -0.114372    -0.300554     0.015806  0.003775 -0.015290 -0.005640  \n",
      "IstFuss     -0.036524    -0.033369     0.054095 -0.003363 -0.023098 -0.020800  \n",
      "IstKrad     -0.041120    -0.081285    -0.003225 -0.019247 -0.011263  0.004639  \n",
      "IstGkfz      1.000000    -0.028578     0.001972 -0.001355 -0.007443 -0.003784  \n",
      "IstSonstige -0.028578     1.000000    -0.015780 -0.004422  0.016368  0.003965  \n",
      "USTRZUSTAND  0.001972    -0.015780     1.000000  0.091100  0.051508 -0.022747  \n",
      "LOCKDOWN    -0.001355    -0.004422     0.091100  1.000000  0.669913 -0.033209  \n",
      "COVID       -0.007443     0.016368     0.051508  0.669913  1.000000  0.011314  \n",
      "FERIEN      -0.003784     0.003965    -0.022747 -0.033209  0.011314  1.000000  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ridge-Regularisierung (L2)\n",
    "##### Vorteile:  \n",
    "Reduziert Overfitting, indem es die Größe der Koeffizienten beschränkt.\n",
    "Funktioniert gut, wenn alle Features relevant sind.\n",
    "Stabilisiert die Lösung, besonders bei multikollinearen Daten.\n",
    "##### Nachteile:  \n",
    "Kann nicht irrelevante Features vollständig eliminieren (Koeffizienten werden nur klein, aber nicht null).\n",
    "Kann bei sehr vielen irrelevanten Features weniger effektiv sein.\n",
    "## Lasso-Regularisierung (L1)\n",
    "##### Vorteile:  \n",
    "Kann irrelevante Features vollständig eliminieren (Koeffizienten werden null), was zu sparsamen Modellen führt.\n",
    "Automatische Feature-Selektion, was die Interpretierbarkeit verbessert.\n",
    "##### Nachteile:\n",
    "Kann bei hoch korrelierten Features instabil sein (wählt zufällig eines der korrelierten Features aus).\n",
    "Kann bei sehr vielen relevanten Features weniger effektiv sein, da es einige Koeffizienten auf null setzen könnte."
   ],
   "id": "fb78cdaf6993c16"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
