{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Hier sind k-fold cross-validation Scores für die Modelle Logistic Regression, Random Forest und K-Nearest Neighbors wobei die Daten gewichtet wurden. (tödliche bzw tödliche/ schwere Unfälle mit Gewichtung 500)\n",
    "\n",
    "einmal für tödliche vs. anderer unfälle als zielvariable, ein weiteres mal mit schweren und tödlichen unfällen vs. leichten unfällen als zielvariabe\n",
    "\n",
    "Mit neuem datensatz, inkl. Lockdown und Covid-Variablen\n"
   ],
   "id": "9c17ff96f164bc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T15:13:04.093093Z",
     "start_time": "2024-06-26T15:12:59.012497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv('../data/GeneralDatensatz18-21ohneGeo-mitLockdown_mitCorona.csv', sep=';')\n",
    "\n",
    "X=df[['UMONAT','USTUNDE','UWOCHENTAG','UART','USTRZUSTAND','BEZ','UTYP1','ULICHTVERH','IstRad','IstPKW','IstFuss','IstKrad','IstGkfz','IstSonstige', 'LOCKDOWN', 'COVID']]\n",
    "#für tödliche Unfälle\n",
    "y=(df['UKATEGORIE'] == 1).astype(int)\n",
    "\n",
    "\n",
    "# KFold-Konfiguration\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Logistische Regression\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight={0:1, 1: 500})\n",
    "\n",
    "accuracy_log = cross_val_score(log_reg, X, y, cv=kf, scoring='accuracy')\n",
    "# es brauch noch ein X_test und y_test \n",
    "\n",
    "pred_log_reg_1 = cross_val_predict(log_reg, X_test, cv=kf)\n",
    "print(\"test classification report: \", classification_report(X, pred_log_reg_1))\n",
    "\n",
    "print(\"Accuracy Logistic Regression (k-fold):\", accuracy_log.mean())\n",
    "\n",
    "\n",
    "recall_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='recall')\n",
    "print(\"Recall Logistic Regression  (k-fold):\", recall_reg.mean())\n",
    "\n",
    "precision_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='precision')\n",
    "print(\"Precision Logistic Regression (k-fold):\", precision_reg.mean())\n",
    "\n",
    "f1_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='f1')\n",
    "print(\"F1 Logistic Regression (k-fold):\", f1_reg.mean())\n",
    "\n",
    "roc_auc_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='roc_auc')\n",
    "print(\"Roc Auc Logistic Regression (k-fold):\", roc_auc_reg.mean())\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "rf_clas = RandomForestClassifier(n_estimators=100, max_depth=5,random_state=42, class_weight={0:1, 1: 1000})\n",
    "accuracy_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy Random Forest (k-fold):\", accuracy_rf.mean())\n",
    "\n",
    "recall_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='recall')\n",
    "print(\"Recall Random Forest (k-fold):\", recall_rf.mean())\n",
    "\n",
    "precision_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='precision')\n",
    "print(\"Precision Random Forest (k-fold):\", precision_rf.mean())\n",
    "\n",
    "f1_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='f1')\n",
    "print(\"F1 Random Forest (k-fold):\", f1_rf.mean())\n",
    "\n",
    "roc_auc_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='roc_auc')\n",
    "print(\"Roc Auc Random Forest (k-fold):\", roc_auc_rf.mean())\n",
    "\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_clas = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "accuracy_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy K-Nearest Neighbors (k-fold):\", accuracy_knn.mean())\n",
    "\n",
    "recall_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='recall')\n",
    "print(\"Recall K-Nearest Neighbors (k-fold):\", recall_knn.mean())\n",
    "\n",
    "precision_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='precision')\n",
    "print(\"Precision K-Nearest Neighbors (k-fold):\", precision_knn.mean())\n",
    "\n",
    "f1_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='f1')\n",
    "print(\"F1 K-Nearest Neighbors (k-fold):\", f1_knn.mean())"
   ],
   "id": "18044ae9a69d39b8",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass-multioutput and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 25\u001B[0m\n\u001B[1;32m     21\u001B[0m accuracy_log \u001B[38;5;241m=\u001B[39m cross_val_score(log_reg, X, y, cv\u001B[38;5;241m=\u001B[39mkf, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     24\u001B[0m pred_log_reg_1 \u001B[38;5;241m=\u001B[39m cross_val_predict(log_reg, X, y, cv\u001B[38;5;241m=\u001B[39mkf)\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest classification report: \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mclassification_report\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred_log_reg_1\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy Logistic Regression (k-fold):\u001B[39m\u001B[38;5;124m\"\u001B[39m, accuracy_log\u001B[38;5;241m.\u001B[39mmean())\n\u001B[1;32m     30\u001B[0m recall_reg \u001B[38;5;241m=\u001B[39m cross_val_score(log_reg, X, y, cv\u001B[38;5;241m=\u001B[39mkf, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecall\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    211\u001B[0m         )\n\u001B[1;32m    212\u001B[0m     ):\n\u001B[0;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    223\u001B[0m     )\n",
      "File \u001B[0;32m~/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2612\u001B[0m, in \u001B[0;36mclassification_report\u001B[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001B[0m\n\u001B[1;32m   2477\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m   2478\u001B[0m     {\n\u001B[1;32m   2479\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2503\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2504\u001B[0m ):\n\u001B[1;32m   2505\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001B[39;00m\n\u001B[1;32m   2506\u001B[0m \n\u001B[1;32m   2507\u001B[0m \u001B[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2609\u001B[0m \u001B[38;5;124;03m    <BLANKLINE>\u001B[39;00m\n\u001B[1;32m   2610\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2612\u001B[0m     y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2614\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2615\u001B[0m         labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\n",
      "File \u001B[0;32m~/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:108\u001B[0m, in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m    105\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 108\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    109\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    110\u001B[0m             type_true, type_pred\n\u001B[1;32m    111\u001B[0m         )\n\u001B[1;32m    112\u001B[0m     )\n\u001B[1;32m    114\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[1;32m    115\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[0;31mValueError\u001B[0m: Classification metrics can't handle a mix of multiclass-multioutput and binary targets"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "zB Logistische Regression:\n",
    "\n",
    "    Recall: 76 % der tödlich Fälle wurden als tödlich erkannt\n",
    "    Precision: 0,8 % der erkannten tödlich Fälle sind tatsächlich tödlich Fälle ( Precision = tp / (tp + fp) , d.h. wenn es viele False Positive gibt, viele fälschlicherweise als tod klassifiziert werden, dann wird der Nenner klein)\n",
    "\n"
   ],
   "id": "c3304ebe6744a61a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T14:57:27.665067Z",
     "start_time": "2024-06-26T14:56:45.298801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#für tödliche und schwere vs. leichte Unfälle\n",
    "y = df['UKATEGORIE'].isin([1, 2]).astype(int)\n",
    "# -> 1 ist schwer oder tödlich, 0 ist leicht\n",
    "\n",
    "# KFold-Konfiguration\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Logistische Regression\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight={0:1, 1: 500})\n",
    "accuracy_log = cross_val_score(log_reg, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy Logistic Regression (k-fold):\", accuracy_log.mean())\n",
    "\n",
    "\n",
    "recall_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='recall')\n",
    "print(\"Recall Logistic Regression  (k-fold):\", recall_reg.mean())\n",
    "\n",
    "precision_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='precision')\n",
    "print(\"Precision Logistic Regression (k-fold):\", precision_reg.mean())\n",
    "\n",
    "f1_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='f1')\n",
    "print(\"F1 Logistic Regression (k-fold):\", f1_reg.mean())\n",
    "\n",
    "roc_auc_reg = cross_val_score(log_reg, X, y, cv=kf, scoring='roc_auc')\n",
    "print(\"Roc Auc Logistic Regression (k-fold):\", roc_auc_reg.mean())\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "rf_clas = RandomForestClassifier(n_estimators=100, max_depth=5,random_state=42, class_weight={0:1, 1: 100})\n",
    "accuracy_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy Random Forest (k-fold):\", accuracy_rf.mean())\n",
    "\n",
    "recall_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='recall')\n",
    "print(\"Recall Random Forest (k-fold):\", recall_rf.mean())\n",
    "\n",
    "precision_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='precision')\n",
    "print(\"Precision Random Forest (k-fold):\", precision_rf.mean())\n",
    "\n",
    "f1_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='f1')\n",
    "print(\"F1 Random Forest (k-fold):\", f1_rf.mean())\n",
    "\n",
    "roc_auc_rf = cross_val_score(rf_clas, X, y, cv=kf, scoring='roc_auc')\n",
    "print(\"Roc Auc Random Forest (k-fold):\", roc_auc_rf.mean())\n",
    "\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_clas = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "accuracy_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Accuracy K-Nearest Neighbors (k-fold):\", accuracy_knn.mean())\n",
    "\n",
    "recall_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='recall')\n",
    "print(\"Recall K-Nearest Neighbors (k-fold):\", recall_knn.mean())\n",
    "\n",
    "precision_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='precision')\n",
    "print(\"Precision K-Nearest Neighbors (k-fold):\", precision_knn.mean())\n",
    "\n",
    "f1_knn = cross_val_score(knn_clas, X, y, cv=kf, scoring='f1')\n",
    "print(\"F1 K-Nearest Neighbors (k-fold):\", f1_knn.mean())"
   ],
   "id": "a0e11be7ad4d7913",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Logistic Regression (k-fold): 0.1537371408091796\n",
      "Recall Logistic Regression  (k-fold): 1.0\n",
      "Precision Logistic Regression (k-fold): 0.1537371408091796\n",
      "F1 Logistic Regression (k-fold): 0.26650076510709847\n",
      "Roc Auc Logistic Regression (k-fold): 0.6395680965144174\n",
      "Accuracy Random Forest (k-fold): 0.1537371408091796\n",
      "Recall Random Forest (k-fold): 1.0\n",
      "Precision Random Forest (k-fold): 0.1537371408091796\n",
      "F1 Random Forest (k-fold): 0.26650076510709847\n",
      "Roc Auc Random Forest (k-fold): 0.66067902832801\n",
      "Accuracy K-Nearest Neighbors (k-fold): 0.8091104764707573\n",
      "Recall K-Nearest Neighbors (k-fold): 0.11347623903069588\n",
      "Precision K-Nearest Neighbors (k-fold): 0.24217967246100125\n",
      "F1 K-Nearest Neighbors (k-fold): 0.15443972821930768\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "zB Logistische Regression:\n",
    "\n",
    "    Recall: 100 % der schweren/tödlichen Fälle wurden als schweren/tödlichen erkannt\n",
    "    Precision: 15 % der erkannten schweren/tödlichen Fälle sind tatsächlich schweren/tödlichen Fälle\n",
    "    ROC AUC Logistic Regression: Der Wert von etwa 0,6393 zeigt, dass das Modell Logistic Regression eine mäßige Fähigkeit hat, zwischen den Klassen zu unterscheiden.\n",
    "\n"
   ],
   "id": "2fb19440cdf14ea4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
