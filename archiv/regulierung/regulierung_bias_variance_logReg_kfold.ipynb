{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Logistische Regression\n",
    "\n",
    "**Lasso-** oder **Ridge-Regularisierung** hilft Overfitting zu vermeiden. Der F-beta Score kann dann verwendet werden, um die Leistung des regulierten Modells zu bewerten.\n",
    "- **Lasso** (L1): Setzt einige Koeffizienten auf null, was einer Feature-Selektion entspricht.\n",
    "- **Ridge** (L2): Schrumpft die Koeffizienten, ohne sie auf null zu setzen, was die Varianz reduziert. \n"
   ],
   "id": "c0b745c8f0a6e936"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Lade den unbalancierten Datensatz.\n",
    "2. Splitte den Datensatz in Trainings- und Testdaten.\n",
    "3. Trainiere ein Modell mit Ridge-Regularisierung.\n",
    "4. Trainiere ein Modell mit Lasso-Regularisierung.\n",
    "5. Berechne den F-beta Score f√ºr beide Modelle auf den Testdaten."
   ],
   "id": "9bd498057a994392"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T13:19:48.597110Z",
     "start_time": "2024-08-07T13:19:03.787130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "\n",
    "# Lade den Datensatz\n",
    "train_data_loaded = pd.read_csv('../data/train_data_2024-08-01.csv')\n",
    "X = train_data_loaded.drop(columns=['UKATEGORIE'])\n",
    "y = train_data_loaded['UKATEGORIE']\n",
    "\n",
    "# Define the f-beta scorer\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Model with Ridge Regularization (L2)\n",
    "model_ridge = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=500, class_weight={0: 1, 1: 9})\n",
    "ridge_scores = cross_val_score(model_ridge, X, y, cv=skf, scoring=fbeta_scorer)\n",
    "print(f'Ridge (L2) F-beta Scores: {ridge_scores}')\n",
    "\n",
    "# Model with Lasso Regularization (L1)\n",
    "model_lasso = LogisticRegression(penalty='l1', solver='liblinear', max_iter= 500, class_weight={0: 1, 1: 9})\n",
    "lasso_scores = cross_val_score(model_lasso, X, y, cv=skf, scoring=fbeta_scorer)\n",
    "print(f'Lasso (L1) F-beta Scores: {lasso_scores}')\n",
    "\n",
    "# Train Ridge model on the full dataset for feature importance\n",
    "model_ridge.fit(X, y)\n",
    "coefficients = model_ridge.coef_\n",
    "\n",
    "# Create a DataFrame with the features and their coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': coefficients.flatten()\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by the absolute values of the coefficients\n",
    "coeff_df['Abs_Coefficient'] = coeff_df['Coefficient'].abs()\n",
    "coeff_df = coeff_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Identify the most important features\n",
    "important_features = coeff_df.head(15)\n",
    "print(important_features[['Feature', 'Coefficient']], '\\n')\n",
    "\n",
    "# Train Lasso model on the full dataset\n",
    "model_lasso.fit(X, y)\n",
    "\n",
    "# Extract the non-null coefficients\n",
    "coef_series = pd.Series(model_lasso.coef_[0])\n",
    "relevant_features = coef_series[coef_series != 0].index\n",
    "\n",
    "# Number of features set to null\n",
    "num_null_features = (coef_series == 0).sum()\n",
    "print(f'Lasso Regularization: Number of features set to null: {num_null_features}')\n",
    "\n",
    "# Create a DataFrame of the relevant features\n",
    "X_relevant = X.iloc[:, relevant_features]\n",
    "\n",
    "# Compute the correlation matrix of the relevant features\n",
    "correlation_matrix = X_relevant.corr()\n",
    "print(\"Correlation matrix of the relevant features:\")\n",
    "print(correlation_matrix)"
   ],
   "id": "45415edb94a35f9c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (L2) F-beta Scores: [0.48941093 0.47996438 0.48560035 0.47680758 0.47735564]\n",
      "Lasso (L1) F-beta Scores: [0.4881196  0.48151795 0.4866277  0.47395274 0.47912756]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasch/Nextcloud/IKT/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Coefficient\n",
      "10      IstFuss     0.588610\n",
      "11      IstKrad     0.536222\n",
      "9        IstPKW    -0.525829\n",
      "12      IstGkfz     0.239196\n",
      "14  USTRZUSTAND    -0.172288\n",
      "7    ULICHTVERH     0.148435\n",
      "13  IstSonstige    -0.128293\n",
      "8        IstRad    -0.095739\n",
      "15     LOCKDOWN    -0.093456\n",
      "5          UART     0.069366\n",
      "6         UTYP1    -0.066737\n",
      "0           BEZ     0.040830\n",
      "2        UMONAT    -0.015615\n",
      "17       FERIEN     0.010070\n",
      "4    UWOCHENTAG    -0.007783 \n",
      "\n",
      "Lasso Regularization: Number of features set to null: 0\n",
      "Correlation matrix of the relevant features:\n",
      "                  BEZ     UJAHR    UMONAT   USTUNDE  UWOCHENTAG      UART  \\\n",
      "BEZ          1.000000  0.016262 -0.001105 -0.019728    0.004234  0.034043   \n",
      "UJAHR        0.016262  1.000000  0.044290  0.010382    0.000579 -0.019961   \n",
      "UMONAT      -0.001105  0.044290  1.000000  0.000265    0.011848 -0.023110   \n",
      "USTUNDE     -0.019728  0.010382  0.000265  1.000000    0.016865 -0.011654   \n",
      "UWOCHENTAG   0.004234  0.000579  0.011848  0.016865    1.000000  0.000621   \n",
      "UART         0.034043 -0.019961 -0.023110 -0.011654    0.000621  1.000000   \n",
      "UTYP1       -0.006259 -0.002802 -0.005130  0.032250    0.001495 -0.283473   \n",
      "ULICHTVERH  -0.026714 -0.008383  0.071050  0.233759    0.015986  0.048186   \n",
      "IstRad      -0.118909  0.008110  0.011817 -0.008445   -0.001897 -0.017276   \n",
      "IstPKW       0.066913 -0.018960 -0.025339  0.029771    0.004643  0.131909   \n",
      "IstFuss      0.016622 -0.028961 -0.016355  0.034862    0.009120  0.388010   \n",
      "IstKrad     -0.006322 -0.008044  0.035563  0.028067   -0.010063 -0.143372   \n",
      "IstGkfz      0.015766 -0.004085 -0.014454 -0.074143   -0.009899 -0.028179   \n",
      "IstSonstige  0.006377  0.024395  0.007821 -0.040327   -0.000001 -0.097953   \n",
      "USTRZUSTAND  0.016541  0.053997  0.023449 -0.000870   -0.001786  0.001156   \n",
      "LOCKDOWN     0.021933  0.403276 -0.004574  0.004128   -0.006948 -0.002427   \n",
      "COVID        0.022127  0.815720  0.110453  0.010513   -0.014890 -0.010124   \n",
      "FERIEN       0.000391  0.099374 -0.041115  0.024188   -0.003562 -0.019250   \n",
      "\n",
      "                UTYP1  ULICHTVERH    IstRad    IstPKW   IstFuss   IstKrad  \\\n",
      "BEZ         -0.006259   -0.026714 -0.118909  0.066913  0.016622 -0.006322   \n",
      "UJAHR       -0.002802   -0.008383  0.008110 -0.018960 -0.028961 -0.008044   \n",
      "UMONAT      -0.005130    0.071050  0.011817 -0.025339 -0.016355  0.035563   \n",
      "USTUNDE      0.032250    0.233759 -0.008445  0.029771  0.034862  0.028067   \n",
      "UWOCHENTAG   0.001495    0.015986 -0.001897  0.004643  0.009120 -0.010063   \n",
      "UART        -0.283473    0.048186 -0.017276  0.131909  0.388010 -0.143372   \n",
      "UTYP1        1.000000   -0.060233 -0.159359  0.069782  0.038497 -0.005861   \n",
      "ULICHTVERH  -0.060233    1.000000 -0.107653  0.020543  0.091589 -0.033449   \n",
      "IstRad      -0.159359   -0.107653  1.000000 -0.245358 -0.173208 -0.293760   \n",
      "IstPKW       0.069782    0.020543 -0.245358  1.000000 -0.137540 -0.132181   \n",
      "IstFuss      0.038497    0.091589 -0.173208 -0.137540  1.000000 -0.121841   \n",
      "IstKrad     -0.005861   -0.033449 -0.293760 -0.132181 -0.121841  1.000000   \n",
      "IstGkfz      0.060579   -0.044863 -0.048897 -0.114372 -0.036524 -0.041120   \n",
      "IstSonstige  0.068536   -0.014776 -0.111932 -0.300554 -0.033369 -0.081285   \n",
      "USTRZUSTAND -0.051445    0.253305 -0.110268  0.015806  0.054095 -0.003225   \n",
      "LOCKDOWN    -0.000509    0.044525 -0.013231  0.003775 -0.003363 -0.019247   \n",
      "COVID       -0.004396    0.001087  0.010581 -0.015290 -0.023098 -0.011263   \n",
      "FERIEN      -0.001381   -0.039335  0.008399 -0.005640 -0.020800  0.004639   \n",
      "\n",
      "              IstGkfz  IstSonstige  USTRZUSTAND  LOCKDOWN     COVID    FERIEN  \n",
      "BEZ          0.015766     0.006377     0.016541  0.021933  0.022127  0.000391  \n",
      "UJAHR       -0.004085     0.024395     0.053997  0.403276  0.815720  0.099374  \n",
      "UMONAT      -0.014454     0.007821     0.023449 -0.004574  0.110453 -0.041115  \n",
      "USTUNDE     -0.074143    -0.040327    -0.000870  0.004128  0.010513  0.024188  \n",
      "UWOCHENTAG  -0.009899    -0.000001    -0.001786 -0.006948 -0.014890 -0.003562  \n",
      "UART        -0.028179    -0.097953     0.001156 -0.002427 -0.010124 -0.019250  \n",
      "UTYP1        0.060579     0.068536    -0.051445 -0.000509 -0.004396 -0.001381  \n",
      "ULICHTVERH  -0.044863    -0.014776     0.253305  0.044525  0.001087 -0.039335  \n",
      "IstRad      -0.048897    -0.111932    -0.110268 -0.013231  0.010581  0.008399  \n",
      "IstPKW      -0.114372    -0.300554     0.015806  0.003775 -0.015290 -0.005640  \n",
      "IstFuss     -0.036524    -0.033369     0.054095 -0.003363 -0.023098 -0.020800  \n",
      "IstKrad     -0.041120    -0.081285    -0.003225 -0.019247 -0.011263  0.004639  \n",
      "IstGkfz      1.000000    -0.028578     0.001972 -0.001355 -0.007443 -0.003784  \n",
      "IstSonstige -0.028578     1.000000    -0.015780 -0.004422  0.016368  0.003965  \n",
      "USTRZUSTAND  0.001972    -0.015780     1.000000  0.091100  0.051508 -0.022747  \n",
      "LOCKDOWN    -0.001355    -0.004422     0.091100  1.000000  0.669913 -0.033209  \n",
      "COVID       -0.007443     0.016368     0.051508  0.669913  1.000000  0.011314  \n",
      "FERIEN      -0.003784     0.003965    -0.022747 -0.033209  0.011314  1.000000  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ridge-Regularisierung (L2)\n",
    "##### Vorteile:  \n",
    "Reduziert Overfitting, indem es die Gr√∂√üe der Koeffizienten beschr√§nkt.\n",
    "Funktioniert gut, wenn alle Features relevant sind.\n",
    "Stabilisiert die L√∂sung, besonders bei multikollinearen Daten.\n",
    "##### Nachteile:  \n",
    "Kann nicht irrelevante Features vollst√§ndig eliminieren (Koeffizienten werden nur klein, aber nicht null).\n",
    "Kann bei sehr vielen irrelevanten Features weniger effektiv sein.\n",
    "## Lasso-Regularisierung (L1)\n",
    "##### Vorteile:  \n",
    "Kann irrelevante Features vollst√§ndig eliminieren (Koeffizienten werden null), was zu sparsamen Modellen f√ºhrt.\n",
    "Automatische Feature-Selektion, was die Interpretierbarkeit verbessert.\n",
    "##### Nachteile:\n",
    "Kann bei hoch korrelierten Features instabil sein (w√§hlt zuf√§llig eines der korrelierten Features aus).\n",
    "Kann bei sehr vielen relevanten Features weniger effektiv sein, da es einige Koeffizienten auf null setzen k√∂nnte."
   ],
   "id": "fb78cdaf6993c16"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
