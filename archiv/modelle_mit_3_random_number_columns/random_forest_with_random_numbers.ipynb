{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-27T18:54:22.717255Z",
     "start_time": "2024-07-27T18:54:22.241576Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T18:54:22.750349Z",
     "start_time": "2024-07-27T18:54:22.718247Z"
    }
   },
   "cell_type": "code",
   "source": "data_with_random_col = pd.read_csv('../data/GeneralDatensatz18-21ohneGeo-mitLockdown.csv', sep=';')",
   "id": "d751561a4588e4e6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T18:54:22.754747Z",
     "start_time": "2024-07-27T18:54:22.751120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# neue Spalte mit random numbers - je größer desto mehr Einfluss hat die Spalte\n",
    "data_with_random_col['randNumCol'] = np.random.randint(0,1000, size=len(data_with_random_col))\n",
    "data_with_random_col['randNumCol2'] = np.random.randint(0,1000, size=len(data_with_random_col))\n",
    "data_with_random_col['randNumCol3'] = np.random.randint(0,1000, size=len(data_with_random_col))"
   ],
   "id": "fa7897670c03ce43",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T18:54:22.756590Z",
     "start_time": "2024-07-27T18:54:22.755340Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9f7e32b8b274388d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T18:54:22.760779Z",
     "start_time": "2024-07-27T18:54:22.757384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# randomForest damit trainieren um zu sehen wie gut die Spalte abschneidet\n",
    "X = data_with_random_col.drop('UKATEGORIE', axis=1)\n",
    "y = data_with_random_col['UKATEGORIE']"
   ],
   "id": "337e4049828b576b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T18:54:22.770510Z",
     "start_time": "2024-07-27T18:54:22.761374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# erstmal ohne kfold (geht kfold hier?)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ],
   "id": "b856df4b5c2a8fc9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T18:54:26.578122Z",
     "start_time": "2024-07-27T18:54:22.771337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ],
   "id": "7ac1954a745cdd8f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T18:54:27.084652Z",
     "start_time": "2024-07-27T18:54:26.578855Z"
    }
   },
   "cell_type": "code",
   "source": "clf.score(X_test, y_test)",
   "id": "6ac6bcbcc8f0082a",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m clf\u001B[38;5;241m.\u001B[39mscore(X_test, y_test)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:668\u001B[0m, in \u001B[0;36mClassifierMixin.score\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    643\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    644\u001B[0m \u001B[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001B[39;00m\n\u001B[1;32m    645\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    664\u001B[0m \u001B[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001B[39;00m\n\u001B[1;32m    665\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    666\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m accuracy_score\n\u001B[0;32m--> 668\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m accuracy_score(y, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(X), sample_weight\u001B[38;5;241m=\u001B[39msample_weight)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:820\u001B[0m, in \u001B[0;36mForestClassifier.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    799\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    800\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    801\u001B[0m \u001B[38;5;124;03m    Predict class for X.\u001B[39;00m\n\u001B[1;32m    802\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    818\u001B[0m \u001B[38;5;124;03m        The predicted classes.\u001B[39;00m\n\u001B[1;32m    819\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 820\u001B[0m     proba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_proba(X)\n\u001B[1;32m    822\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    823\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\u001B[38;5;241m.\u001B[39mtake(np\u001B[38;5;241m.\u001B[39margmax(proba, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:862\u001B[0m, in \u001B[0;36mForestClassifier.predict_proba\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    860\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    861\u001B[0m \u001B[38;5;66;03m# Check data\u001B[39;00m\n\u001B[0;32m--> 862\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_X_predict(X)\n\u001B[1;32m    864\u001B[0m \u001B[38;5;66;03m# Assign chunk of trees to jobs\u001B[39;00m\n\u001B[1;32m    865\u001B[0m n_jobs, _, _ \u001B[38;5;241m=\u001B[39m _partition_estimators(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_estimators, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:602\u001B[0m, in \u001B[0;36mBaseForest._validate_X_predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    599\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    600\u001B[0m \u001B[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001B[39;00m\n\u001B[1;32m    601\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 602\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(X, dtype\u001B[38;5;241m=\u001B[39mDTYPE, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    603\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(X) \u001B[38;5;129;01mand\u001B[39;00m (X\u001B[38;5;241m.\u001B[39mindices\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc \u001B[38;5;129;01mor\u001B[39;00m X\u001B[38;5;241m.\u001B[39mindptr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc):\n\u001B[1;32m    604\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo support for np.int64 index based sparse matrices\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:565\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    563\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    564\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[0;32m--> 565\u001B[0m     X \u001B[38;5;241m=\u001B[39m check_array(X, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[1;32m    566\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[1;32m    567\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:921\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    915\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    916\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    917\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    918\u001B[0m         )\n\u001B[1;32m    920\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m--> 921\u001B[0m         _assert_all_finite(\n\u001B[1;32m    922\u001B[0m             array,\n\u001B[1;32m    923\u001B[0m             input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[1;32m    924\u001B[0m             estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[1;32m    925\u001B[0m             allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    926\u001B[0m         )\n\u001B[1;32m    928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    929\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:161\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    147\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    149\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    160\u001B[0m     )\n\u001B[0;32m--> 161\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[0;31mValueError\u001B[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rf_feature_importances = pd.DataFrame(clf.feature_importances_, index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(\"Wichtigkeit der Merkmale (Random Forest):\")\n",
    "print(rf_feature_importances)"
   ],
   "id": "bb7d9149b06de3e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dbea8af691899d97",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
